---
phase: 11-session-end-knowledge-extraction
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - get-shit-done/bin/session-analyzer.js
  - get-shit-done/bin/analysis-prompts.js
autonomous: true

must_haves:
  truths:
    - "Haiku 4.5 can analyze a session transcript and return structured JSON with decisions, reasoning patterns, and meta-knowledge"
    - "Extraction prompts constrain Haiku to only extract explicitly stated content with context snippets for grounding"
    - "Output is validated against Zod-like schemas before being returned, preventing malformed data"
  artifacts:
    - path: "get-shit-done/bin/session-analyzer.js"
      provides: "Core Haiku analysis orchestrator with multi-pass extraction"
      exports: ["analyzeSession", "extractDecisions", "extractReasoningPatterns", "extractMetaKnowledge"]
    - path: "get-shit-done/bin/analysis-prompts.js"
      provides: "Structured prompt templates for each extraction type"
      exports: ["DECISION_PROMPT", "REASONING_PROMPT", "META_KNOWLEDGE_PROMPT", "buildExtractionPrompt"]
  key_links:
    - from: "get-shit-done/bin/session-analyzer.js"
      to: "@anthropic-ai/sdk"
      via: "Haiku API calls"
      pattern: "new Anthropic.*messages\\.create"
    - from: "get-shit-done/bin/session-analyzer.js"
      to: "get-shit-done/bin/analysis-prompts.js"
      via: "require import"
      pattern: "require.*analysis-prompts"
---

<objective>
Build the core session analysis engine that uses Claude Haiku 4.5 to extract structured knowledge from session transcripts.

Purpose: Replace regex-only extraction (Phase 4) with semantic LLM analysis that captures implicit decisions, reasoning chains, and meta-knowledge that keywords cannot detect.

Output: Two modules - `session-analyzer.js` (orchestrator) and `analysis-prompts.js` (prompt templates) - that accept session JSONL entries and return validated structured insights.
</objective>

<execution_context>
@/Users/ollorin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ollorin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-session-end-knowledge-extraction-implement-haiku-based-analysis-of-completed-sessions-to-extract-reasoning-patterns-and-decisions-beyond-keyword-matching/11-RESEARCH.md
@get-shit-done/bin/knowledge-extraction.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create analysis prompt templates module</name>
  <files>get-shit-done/bin/analysis-prompts.js</files>
  <action>
Create `analysis-prompts.js` as a CommonJS module (matching existing knowledge system pattern) with three specialized extraction prompt templates:

1. **DECISION_PROMPT** - Extracts explicit decisions made during session. Requires: decision statement, reasoning, alternatives considered, confidence (high/medium/low), context_snippet (exact quote from session proving decision exists). Include the constraint: "Only extract decisions explicitly stated in transcript. If uncertain, set confidence to 'low'."

2. **REASONING_PROMPT** - Extracts reasoning patterns (chain-of-thought, debugging approaches, tradeoff analysis, meta-reasoning). Requires: pattern_type, description, trigger condition, outcome, reusable boolean, context_snippet.

3. **META_KNOWLEDGE_PROMPT** - Extracts higher-order insights (user preferences, working principles, constraints, learning patterns). Requires: category (preference/principle/constraint/learning_pattern), statement, evidence array, confidence, scope (project/global), context_snippet.

Each prompt template:
- Uses `{{SESSION_ENTRIES}}` placeholder for session text injection
- Specifies exact JSON output schema in the prompt
- Includes grounding constraint requiring context_snippet citation
- Instructs Haiku to output ONLY a JSON array (no markdown fences, no preamble)
- Uses temperature guidance note (0.3 for extraction, not generation)

Export a `buildExtractionPrompt(templateName, sessionText)` function that replaces the placeholder and returns the complete prompt string.

Also export the output schemas as plain objects (not Zod - avoid adding dependency) with a `validateExtraction(type, data)` function that checks required fields and types. Return `{ valid: true, data }` or `{ valid: false, errors: [] }`.

Schema validation rules:
- decision: decision (string, min 10 chars), reasoning (string), alternatives_considered (array), confidence (enum: high/medium/low), context_snippet (string)
- reasoning_pattern: pattern_type (string), description (string, min 10 chars), trigger (string), outcome (string), reusable (boolean), context_snippet (string)
- meta_knowledge: category (enum: preference/principle/constraint/learning_pattern), statement (string, min 10 chars), evidence (array, min 1), confidence (enum: high/medium/low), scope (enum: project/global), context_snippet (string)
  </action>
  <verify>
Run `node -e "const p = require('./get-shit-done/bin/analysis-prompts.js'); console.log(Object.keys(p)); console.log(p.buildExtractionPrompt('decision', 'test session').includes('SESSION_ENTRIES') === false); const v = p.validateExtraction('decision', { decision: 'Use Haiku for analysis', reasoning: 'cost', alternatives_considered: ['Sonnet'], confidence: 'high', context_snippet: 'quote' }); console.log(v.valid);"` — should output exported keys, true (placeholder replaced), and true (validation passes).
  </verify>
  <done>Three prompt templates exported with schema validation. buildExtractionPrompt replaces placeholders. validateExtraction validates all three types with correct field checks.</done>
</task>

<task type="auto">
  <name>Task 2: Create session analyzer with Haiku integration</name>
  <files>get-shit-done/bin/session-analyzer.js</files>
  <action>
Create `session-analyzer.js` as a CommonJS module with the core analysis orchestrator.

**Dependencies:** Uses `@anthropic-ai/sdk` which is already installed at the project root (Phase 8 installed it). Verify with `require('@anthropic-ai/sdk')`. If not available, the module should gracefully degrade (return empty results with a warning).

**Session entry formatting function** `formatEntriesForPrompt(entries)`:
- Filter to only relevant entry types: 'question', 'answer', 'bot_response', 'user_message'
- Skip 'session_metadata', 'heartbeat', 'session_close' types
- Format each entry as: `[{index}] [{timestamp}] {TYPE}: {content}`
- For 'question' type: include `entry.question` and optionally `entry.context`
- For 'answer' type: include `entry.answer`
- For 'bot_response'/'user_message': include `entry.content`
- Join with double newlines

**Core function** `async analyzeSession(entries, options = {})`:
- Options: `{ extractDecisions: true, extractReasoning: true, extractMetaKnowledge: true, model: 'claude-haiku-4-5-20250514' }`
- Initialize Anthropic client (lazy, cached) using `ANTHROPIC_API_KEY` env var
- If no API key, return `{ insights: [], error: 'ANTHROPIC_API_KEY not set' }`
- Format entries with `formatEntriesForPrompt`
- Run up to 3 Haiku passes based on options (decision, reasoning, meta-knowledge)
- For each pass:
  - Build prompt using `analysis-prompts.js` `buildExtractionPrompt`
  - Call `anthropic.messages.create({ model, max_tokens: 2000, temperature: 0.3, messages: [{ role: 'user', content: prompt }] })`
  - Parse JSON from response text (handle markdown fences if Haiku wraps in ```json)
  - Validate each item with `validateExtraction`
  - Filter to only valid items
  - Tag each with `{ type: extractionType, ...validatedData }`
- Deduplicate across passes using content similarity (simple string comparison for now - canonical hash of decision/statement/description field)
- Return `{ insights: [...], stats: { total_passes, total_raw, total_valid, total_deduped }, model, input_tokens, output_tokens }`

**Export individual extractors too** for targeted use:
- `extractDecisions(entries, options)` - single-pass decision extraction
- `extractReasoningPatterns(entries, options)` - single-pass reasoning extraction
- `extractMetaKnowledge(entries, options)` - single-pass meta-knowledge extraction

**Error handling:**
- Wrap each Haiku call in try/catch. On API error, log to stderr and continue with remaining passes
- If JSON parsing fails, attempt to extract JSON from markdown code fences
- If all passes fail, return empty insights with error details in stats

Do NOT use tiktoken for token counting here (avoid dependency complexity). Track tokens from Anthropic API response `usage` field directly.
  </action>
  <verify>
Run `node -e "const a = require('./get-shit-done/bin/session-analyzer.js'); console.log(Object.keys(a)); const f = a.formatEntriesForPrompt([{type:'question',question:'test?',timestamp:'2026-01-01T00:00:00Z'},{type:'heartbeat',timestamp:'2026-01-01T00:01:00Z'},{type:'answer',answer:'yes',timestamp:'2026-01-01T00:02:00Z'}]); console.log(f.includes('QUESTION: test?')); console.log(!f.includes('heartbeat'));"` — should output exported keys, true (question formatted), true (heartbeat filtered).
  </verify>
  <done>Session analyzer module loads without errors, formatEntriesForPrompt correctly filters and formats entries, analyzeSession function exported with multi-pass Haiku orchestration, graceful degradation when API key missing.</done>
</task>

</tasks>

<verification>
1. Both modules load without errors: `node -e "require('./get-shit-done/bin/session-analyzer.js'); require('./get-shit-done/bin/analysis-prompts.js'); console.log('OK')"`
2. Prompt templates contain required grounding constraints (context_snippet, JSON-only output)
3. Schema validation correctly rejects malformed data and accepts valid data
4. Entry formatter filters non-content types and formats remaining entries
5. Analyzer gracefully handles missing ANTHROPIC_API_KEY
</verification>

<success_criteria>
Two CommonJS modules that together provide Haiku-based session analysis: prompt templates with schema validation, and an orchestrator that runs multi-pass extraction with error handling. No external dependencies beyond @anthropic-ai/sdk (already installed).
</success_criteria>

<output>
After completion, create `.planning/phases/11-session-end-knowledge-extraction-implement-haiku-based-analysis-of-completed-sessions-to-extract-reasoning-patterns-and-decisions-beyond-keyword-matching/11-01-SUMMARY.md`
</output>
