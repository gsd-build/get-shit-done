---
phase: 09-hook-based-documentation-compression
plan: 03
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - ~/.claude/get-shit-done/bin/hooks/doc-compression-hook.js
  - ~/.claude/get-shit-done/bin/hooks/config.js
  - ~/.claude/get-shit-done/bin/hooks/compression-cache.js
  - ~/.claude/settings.json
autonomous: true

must_haves:
  truths:
    - "PreToolUse hook intercepts Read operations on GSD documentation files"
    - "Hook returns compressed summary via additionalContext"
    - "Files smaller than threshold are passed through uncompressed"
    - "Hook configuration stored in hooks/config.js"
    - "Cache prevents redundant compression using content hash + mtime keys"
    - "Cache entries expire after cache_ttl seconds"
  artifacts:
    - path: "~/.claude/get-shit-done/bin/hooks/doc-compression-hook.js"
      provides: "PreToolUse hook for documentation compression"
      min_lines: 60
    - path: "~/.claude/get-shit-done/bin/hooks/config.js"
      provides: "Hook configuration with compression settings"
      exports: ["loadHookConfig", "saveHookConfig", "DEFAULT_HOOK_CONFIG"]
    - path: "~/.claude/get-shit-done/bin/hooks/compression-cache.js"
      provides: "File-based compression cache with hash+mtime keys"
      exports: ["CompressionCache"]
    - path: "~/.claude/settings.json"
      provides: "Hook registration for PreToolUse"
      contains: "doc-compression-hook.js"
  key_links:
    - from: "doc-compression-hook.js"
      to: "header-extractor.js"
      via: "require('../compression/header-extractor')"
      pattern: "HeaderExtractor"
    - from: "doc-compression-hook.js"
      to: "config.js"
      via: "require('./config')"
      pattern: "loadHookConfig"
    - from: "doc-compression-hook.js"
      to: "compression-cache.js"
      via: "require('./compression-cache')"
      pattern: "CompressionCache"
    - from: "settings.json"
      to: "doc-compression-hook.js"
      via: "hooks.PreToolUse"
      pattern: "doc-compression-hook"
---

<objective>
Create PreToolUse hook for automatic GSD documentation compression with caching and integrate with Claude Code hooks system.

Purpose: Automatically compress large GSD docs (RESEARCH.md, PLAN.md, STATE.md) to reduce context consumption by 60-70%. Cache prevents redundant compression using content hash + mtime keys.
Output: Working PreToolUse hook registered in settings.json with configurable compression settings and file-based cache.
</objective>

<execution_context>
@/Users/ollorin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ollorin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/09-hook-based-documentation-compression-optimize-context-injection-by-extracting-ai-friendly-headers-from-docs-and-injecting-only-summaries-with-absolute-links-instead-of-full-content/09-RESEARCH.md

Reference 09-01-SUMMARY.md for header-extractor.js implementation:
@.planning/phases/09-hook-based-documentation-compression-optimize-context-injection-by-extracting-ai-friendly-headers-from-docs-and-injecting-only-summaries-with-absolute-links-instead-of-full-content/09-01-SUMMARY.md

Note: This plan depends only on 09-01 (header-extractor), NOT 09-02 (routing extensions).
09-02's routing/SKILL.md extensions are independent of the hook system and can run in parallel.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create hook configuration module</name>
  <files>~/.claude/get-shit-done/bin/hooks/config.js</files>
  <action>
  Create the hooks/config.js module with compression configuration:

  1. **DEFAULT_HOOK_CONFIG** object:
  ```javascript
  const DEFAULT_HOOK_CONFIG = {
    enabled: true,
    compression: {
      enabled: true,
      strategy: 'header-extraction',
      min_file_lines: 500,           // Skip files smaller than 500 lines
      target_reduction: 65,           // Aim for 65% reduction
      cache_ttl: 300,                 // 5 minutes cache TTL
      patterns: [
        '**/*-RESEARCH.md',
        '**/*-PLAN.md',
        '**/*-CONTEXT.md',
        '**/STATE.md',
        '**/ROADMAP.md',
        '**/PROJECT.md'
      ],
      exclude: [
        '**/*-SUMMARY.md',           // Already compressed
        '**/README.md'               // Usually short
      ],
      fallback: 'pass-through'       // On error: pass-through (don't block)
    }
  };
  ```

  2. **loadHookConfig()** function:
     - Reads config from ~/.claude/get-shit-done/hook-config.json
     - Returns merged config (defaults + user overrides)
     - Creates config file with defaults if missing

  3. **saveHookConfig(config)** function:
     - Writes config to hook-config.json
     - Used for runtime config updates (enable/disable compression)

  4. **matchesPattern(filePath, patterns, excludes)** function:
     - Uses minimatch for glob pattern matching
     - Returns true if filePath matches any pattern and no excludes

  Export all functions and DEFAULT_HOOK_CONFIG.
  </action>
  <verify>
  ```bash
  mkdir -p ~/.claude/get-shit-done/bin/hooks
  node -e "
    const { DEFAULT_HOOK_CONFIG, loadHookConfig } = require('$HOME/.claude/get-shit-done/bin/hooks/config');
    console.log('Default config:', JSON.stringify(DEFAULT_HOOK_CONFIG.compression, null, 2));
    const config = loadHookConfig();
    console.log('Loaded config enabled:', config.compression.enabled);
  "
  ```
  </verify>
  <done>loadHookConfig returns merged configuration with compression settings. Config file created at hook-config.json if missing.</done>
</task>

<task type="auto">
  <name>Task 2: Create compression cache module</name>
  <files>~/.claude/get-shit-done/bin/hooks/compression-cache.js</files>
  <action>
  Create compression-cache.js with file-based caching using content hash + mtime keys:

  1. **CompressionCache class:**
  ```javascript
  const fs = require('fs');
  const path = require('path');
  const crypto = require('crypto');

  const CACHE_DIR = path.join(process.env.HOME, '.claude', 'get-shit-done', 'compression-cache');

  class CompressionCache {
    constructor(ttlSeconds = 300) {
      this.ttl = ttlSeconds * 1000; // Convert to ms
      this.ensureCacheDir();
    }

    ensureCacheDir() {
      if (!fs.existsSync(CACHE_DIR)) {
        fs.mkdirSync(CACHE_DIR, { recursive: true });
      }
    }

    // Generate cache key from file path, content hash, and mtime
    getCacheKey(filePath, content, mtime) {
      const hash = crypto.createHash('md5')
        .update(filePath + content + mtime.toString())
        .digest('hex');
      return hash;
    }

    // Get cached summary if valid
    get(filePath, content, mtime) {
      const key = this.getCacheKey(filePath, content, mtime);
      const cachePath = path.join(CACHE_DIR, key + '.json');

      if (!fs.existsSync(cachePath)) return null;

      const cached = JSON.parse(fs.readFileSync(cachePath, 'utf-8'));
      const age = Date.now() - cached.timestamp;

      if (age > this.ttl) {
        fs.unlinkSync(cachePath); // Expired, remove
        return null;
      }

      return cached.summary;
    }

    // Store summary in cache
    set(filePath, content, mtime, summary) {
      const key = this.getCacheKey(filePath, content, mtime);
      const cachePath = path.join(CACHE_DIR, key + '.json');

      fs.writeFileSync(cachePath, JSON.stringify({
        timestamp: Date.now(),
        filePath,
        summary
      }));
    }

    // Clear all cached entries
    clear() {
      if (fs.existsSync(CACHE_DIR)) {
        const files = fs.readdirSync(CACHE_DIR);
        for (const file of files) {
          fs.unlinkSync(path.join(CACHE_DIR, file));
        }
      }
    }

    // Get cache stats
    stats() {
      if (!fs.existsSync(CACHE_DIR)) return { entries: 0, totalSize: 0 };
      const files = fs.readdirSync(CACHE_DIR);
      let totalSize = 0;
      for (const file of files) {
        totalSize += fs.statSync(path.join(CACHE_DIR, file)).size;
      }
      return { entries: files.length, totalSize };
    }
  }

  module.exports = { CompressionCache, CACHE_DIR };
  ```

  2. **Cache key design:**
     - Uses MD5 hash of: filePath + content + mtime
     - Content hash ensures cache invalidates on file changes
     - mtime provides fast change detection without full content read
     - Combined key prevents collisions and ensures freshness

  3. **Cache storage:**
     - Location: ~/.claude/get-shit-done/compression-cache/
     - Format: {hash}.json files containing timestamp + summary
     - TTL enforcement on read (lazy expiration)
  </action>
  <verify>
  ```bash
  node -e "
    const { CompressionCache } = require('$HOME/.claude/get-shit-done/bin/hooks/compression-cache');
    const cache = new CompressionCache(300);
    cache.set('/test/file.md', 'content', 12345, '# Summary');
    const result = cache.get('/test/file.md', 'content', 12345);
    console.log('Cached:', result);
    console.log('Stats:', cache.stats());
    cache.clear();
  "
  ```
  </verify>
  <done>CompressionCache stores and retrieves summaries using content hash + mtime keys. Cache entries expire after TTL.</done>
</task>

<task type="auto">
  <name>Task 3: Create PreToolUse compression hook with caching</name>
  <files>~/.claude/get-shit-done/bin/hooks/doc-compression-hook.js</files>
  <action>
  Create doc-compression-hook.js that intercepts Read operations WITH CACHE INTEGRATION:

  1. **Shebang and imports:**
  ```javascript
  #!/usr/bin/env node

  const fs = require('fs');
  const path = require('path');
  const { HeaderExtractor } = require('../compression/header-extractor');
  const { loadHookConfig, matchesPattern } = require('./config');
  const { CompressionCache } = require('./compression-cache');
  ```

  2. **DOC_PATTERNS regex array** for quick pattern check:
  ```javascript
  const DOC_PATTERNS = [
    /.*-RESEARCH\.md$/,
    /.*-PLAN\.md$/,
    /.*-CONTEXT\.md$/,
    /STATE\.md$/,
    /ROADMAP\.md$/,
    /PROJECT\.md$/
  ];
  ```

  3. **main() async function with caching:**
     - Reads stdin (JSON: { tool, parameters })
     - Exit 0 if tool !== 'Read' (pass through)
     - Exit 0 if file_path missing
     - Check if file matches DOC_PATTERNS
     - Load config, check if compression enabled
     - Get file stat for mtime
     - **CHECK CACHE FIRST:**
       ```javascript
       const config = loadHookConfig();
       const cache = new CompressionCache(config.compression.cache_ttl);
       const content = fs.readFileSync(absolutePath, 'utf-8');
       const stat = fs.statSync(absolutePath);

       // Try cache first
       const cached = cache.get(absolutePath, content, stat.mtimeMs);
       if (cached) {
         console.log(JSON.stringify({
           additionalContext: cached,
           metadata: { fromCache: true, path: absolutePath }
         }));
         process.exit(0);
       }
       ```
     - If not cached, compress and STORE IN CACHE:
       ```javascript
       const { summary } = extractor.extractSummary(content, absolutePath);
       cache.set(absolutePath, content, stat.mtimeMs, summary);
       ```
     - Output JSON: { additionalContext: summary, metadata: { fromCache: false, ... } }

  4. **Error handling:**
     - Log errors to stderr (not stdout, which is hook output)
     - Always exit 0 to not block reads
     - Include error message in metadata if compression fails

  Make file executable: `chmod +x doc-compression-hook.js`
  </action>
  <verify>
  ```bash
  chmod +x ~/.claude/get-shit-done/bin/hooks/doc-compression-hook.js
  # First call - should compress and cache
  echo '{"tool": "Read", "parameters": {"file_path": "'$HOME'/get-shit-done/.planning/ROADMAP.md"}}' | node ~/.claude/get-shit-done/bin/hooks/doc-compression-hook.js | jq '.metadata.fromCache'
  # Second call - should hit cache
  echo '{"tool": "Read", "parameters": {"file_path": "'$HOME'/get-shit-done/.planning/ROADMAP.md"}}' | node ~/.claude/get-shit-done/bin/hooks/doc-compression-hook.js | jq '.metadata.fromCache'
  ```
  </verify>
  <done>Hook outputs JSON with additionalContext. First call compresses and caches (fromCache: false). Second call returns cached (fromCache: true).</done>
</task>

<task type="auto">
  <name>Task 4: Register hook in Claude Code settings</name>
  <files>~/.claude/settings.json</files>
  <action>
  Update ~/.claude/settings.json to register the PreToolUse hook:

  1. Read existing settings.json (or create if missing)

  2. Add hooks configuration:
  ```json
  {
    "hooks": {
      "PreToolUse": [
        {
          "matcher": "Read",
          "hooks": [
            {
              "type": "command",
              "command": "node ~/.claude/get-shit-done/bin/hooks/doc-compression-hook.js"
            }
          ]
        }
      ]
    }
  }
  ```

  3. Preserve existing settings (merge, don't replace)

  4. If hooks.PreToolUse already exists, append to the array rather than replace

  Note: Claude Code hook format may vary. Check Claude Code docs for exact format.
  Common formats:
  - Array of hook objects with matcher + hooks
  - Object with tool names as keys

  Start with the array format from research, adjust if needed based on actual Claude Code requirements.
  </action>
  <verify>
  ```bash
  cat ~/.claude/settings.json | jq '.hooks.PreToolUse'
  ```
  </verify>
  <done>settings.json contains PreToolUse hook registration pointing to doc-compression-hook.js</done>
</task>

</tasks>

<verification>
Run the following to verify the complete implementation:

```bash
# 1. Test config loading
node -e "
  const { loadHookConfig } = require('$HOME/.claude/get-shit-done/bin/hooks/config');
  const cfg = loadHookConfig();
  console.log('Compression enabled:', cfg.compression.enabled);
  console.log('Min lines:', cfg.compression.min_file_lines);
  console.log('Cache TTL:', cfg.compression.cache_ttl);
"

# 2. Test cache module
node -e "
  const { CompressionCache } = require('$HOME/.claude/get-shit-done/bin/hooks/compression-cache');
  const cache = new CompressionCache(300);
  console.log('Cache stats:', cache.stats());
"

# 3. Test hook execution on matching file (first call - no cache)
echo '{"tool": "Read", "parameters": {"file_path": "'$HOME'/get-shit-done/.planning/ROADMAP.md"}}' | node ~/.claude/get-shit-done/bin/hooks/doc-compression-hook.js | jq '.metadata'

# 4. Test hook execution (second call - from cache)
echo '{"tool": "Read", "parameters": {"file_path": "'$HOME'/get-shit-done/.planning/ROADMAP.md"}}' | node ~/.claude/get-shit-done/bin/hooks/doc-compression-hook.js | jq '.metadata.fromCache'
# Should output: true

# 5. Test hook pass-through on non-matching file
echo '{"tool": "Read", "parameters": {"file_path": "'$HOME'/get-shit-done/README.md"}}' | node ~/.claude/get-shit-done/bin/hooks/doc-compression-hook.js
# Should produce no output (pass through)

# 6. Test hook pass-through on non-Read tool
echo '{"tool": "Write", "parameters": {"file_path": "/test.md"}}' | node ~/.claude/get-shit-done/bin/hooks/doc-compression-hook.js
# Should produce no output (pass through)

# 7. Verify settings.json hook registration
cat ~/.claude/settings.json | jq '.hooks'
```

Expected:
- Config loads with compression settings including cache_ttl
- Cache module creates and manages cache entries
- First hook call compresses and caches (fromCache: false)
- Second hook call returns cached (fromCache: true)
- Non-matching files pass through (no output)
- Non-Read tools pass through
- settings.json has PreToolUse hook registered
</verification>

<success_criteria>
1. hooks/config.js exports loadHookConfig, saveHookConfig, DEFAULT_HOOK_CONFIG
2. compression-cache.js exports CompressionCache class
3. Cache uses content hash + mtime as cache key
4. Cache entries expire after cache_ttl seconds
5. doc-compression-hook.js intercepts Read operations
6. Hook checks cache BEFORE compressing
7. Hook stores compressed summary in cache
8. Hook compresses files matching DOC_PATTERNS
9. Hook passes through files under min_file_lines threshold
10. Hook outputs JSON with additionalContext on compression
11. Hook includes fromCache metadata indicating cache hit/miss
12. Hook handles errors gracefully (exit 0, don't block reads)
13. settings.json registers PreToolUse hook
</success_criteria>

<output>
After completion, create `.planning/phases/09-hook-based-documentation-compression-optimize-context-injection-by-extracting-ai-friendly-headers-from-docs-and-injecting-only-summaries-with-absolute-links-instead-of-full-content/09-03-SUMMARY.md`
</output>
