---
phase: 09-hook-based-documentation-compression
plan: 02
type: execute
wave: 2
depends_on: [09-01]
files_modified:
  - get-shit-done/bin/hooks/doc-compression-hook.js
  - get-shit-done/bin/hooks/compression-cache.js
  - get-shit-done/bin/hooks/config.js
autonomous: true

must_haves:
  truths:
    - "PreToolUse hook intercepts Read tool calls for documentation files"
    - "Compressed summaries are injected via additionalContext"
    - "Cache prevents redundant compression with content hash + mtime keys"
    - "Hook failures gracefully fall back to normal Read behavior"
  artifacts:
    - path: "get-shit-done/bin/hooks/doc-compression-hook.js"
      provides: "PreToolUse handler for documentation compression"
      exports: ["docCompressionHook"]
    - path: "get-shit-done/bin/hooks/compression-cache.js"
      provides: "Content-hash based cache for compressed documents"
      exports: ["CompressionCache"]
  key_links:
    - from: "get-shit-done/bin/hooks/doc-compression-hook.js"
      to: "get-shit-done/bin/compression/header-extractor.js"
      via: "HeaderExtractor import"
      pattern: "require.*header-extractor"
    - from: "get-shit-done/bin/hooks/doc-compression-hook.js"
      to: "get-shit-done/bin/hooks/compression-cache.js"
      via: "cache lookup/save"
      pattern: "cache\\.(get|set)"
---

<objective>
Create the PreToolUse hook handler that intercepts Read tool calls and injects compressed documentation.

Purpose: This hook is the core integration point - it intercepts Claude Code Read operations for documentation files and injects compressed summaries with file links, reducing context consumption by 60-70%.

Output: Hook handler module, cache system, and updated hook configuration.
</objective>

<execution_context>
@/Users/ollorin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ollorin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-hook-based-documentation-compression-optimize-context-injection-by-extracting-ai-friendly-headers-from-docs-and-injecting-only-summaries-with-absolute-links-instead-of-full-content/09-RESEARCH.md
@.planning/phases/09-hook-based-documentation-compression-optimize-context-injection-by-extracting-ai-friendly-headers-from-docs-and-injecting-only-summaries-with-absolute-links-instead-of-full-content/09-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CompressionCache module</name>
  <files>get-shit-done/bin/hooks/compression-cache.js</files>
  <action>
    Create `get-shit-done/bin/hooks/compression-cache.js` with content-hash based caching:

    **Class: CompressionCache**
    - Constructor: `constructor(options = {})` with `{ cacheDir, ttlSeconds = 300 }`
    - Method: `getCacheKey(absolutePath, content)` returns `${contentHash}:${mtime}` key
    - Method: `get(absolutePath, content)` returns cached compressed string or null
    - Method: `set(absolutePath, content, compressed, metrics)` stores compressed result
    - Method: `clear()` removes all cache entries
    - Method: `getStats()` returns `{ hits, misses, entries, totalSaved }`

    **Cache storage:**
    - Default location: `.planning/.doc-compression-cache/`
    - Each entry stored as JSON: `{ compressed, metrics, timestamp, originalHash }`
    - File naming: `{contentHash-first-8}.json` for fast lookup
    - TTL: 5 minutes default (active development invalidation)

    **Content hash algorithm:**
    - Use Node.js crypto: `crypto.createHash('sha256').update(content).digest('hex').slice(0, 16)`
    - Combine with mtime for cache key (handles git operations that preserve mtime)

    **Cache validation on get:**
    1. Check file exists in cache dir
    2. Verify TTL not expired
    3. Verify content hash matches (handles edits between cached and current)
    4. Return cached compressed string or null

    **Export:** `{ CompressionCache }`
  </action>
  <verify>
    ```bash
    cd get-shit-done && node -e "
    const { CompressionCache } = require('./bin/hooks/compression-cache');
    const cache = new CompressionCache({ cacheDir: '/tmp/test-compression-cache' });

    // Test set and get
    const content = 'Test document content';
    const compressed = 'Compressed version';
    cache.set('/test/doc.md', content, compressed, { saved: 100 });

    const retrieved = cache.get('/test/doc.md', content);
    console.log('Cache hit:', retrieved === compressed);

    // Test cache miss on different content
    const miss = cache.get('/test/doc.md', 'Different content');
    console.log('Cache miss on changed content:', miss === null);

    console.log('Stats:', cache.getStats());
    cache.clear();
    "
    ```
    Should show cache hit for same content, miss for changed content.
  </verify>
  <done>CompressionCache provides content-hash based caching with TTL, statistics tracking, and proper invalidation on content changes</done>
</task>

<task type="auto">
  <name>Task 2: Create doc-compression-hook handler</name>
  <files>get-shit-done/bin/hooks/doc-compression-hook.js</files>
  <action>
    Create `get-shit-done/bin/hooks/doc-compression-hook.js` as the PreToolUse hook handler:

    **Main function: docCompressionHook(hookInput)**

    The hook receives JSON from Claude Code via stdin with this structure:
    ```json
    {
      "tool": "Read",
      "tool_input": {
        "file_path": "/absolute/path/to/file.md"
      }
    }
    ```

    **Processing flow:**
    1. Parse stdin JSON
    2. Check if tool === 'Read'
    3. Check if file_path matches documentation patterns
    4. If not a doc file, output `{"decision": "continue"}` and exit
    5. If doc file but too small (<500 lines), output `{"decision": "continue"}`
    6. Check cache for compressed version
    7. If cache miss: read file, compress with HeaderExtractor, cache result
    8. Output JSON with additionalContext:
       ```json
       {
         "decision": "continue",
         "additionalContext": "<compressed summary with file link>"
       }
       ```

    **Documentation patterns to match:**
    ```javascript
    const DOC_PATTERNS = [
      /.*-RESEARCH\.md$/,
      /.*-PLAN\.md$/,
      /.*-CONTEXT\.md$/,
      /STATE\.md$/,
      /ROADMAP\.md$/,
      /PROJECT\.md$/,
      /REQUIREMENTS\.md$/
    ];
    ```

    **Size threshold:**
    - Skip compression if file < 500 lines or < 15KB
    - Calculate: `content.split('\n').length` and `Buffer.byteLength(content, 'utf8')`

    **Error handling (CRITICAL):**
    - Wrap ALL logic in try/catch
    - On ANY error: output `{"decision": "continue"}` to fall back to normal Read
    - Log errors to stderr (does not affect hook output)
    - Never output malformed JSON - always valid response

    **Implementation pattern:**
    ```javascript
    #!/usr/bin/env node
    const readline = require('readline');

    async function main() {
      try {
        // Read hook input from stdin
        const input = await readStdin();
        const hookData = JSON.parse(input);

        // Process and output result
        const result = await processHook(hookData);
        console.log(JSON.stringify(result));
      } catch (err) {
        // Always fall back gracefully
        console.error('[doc-compression] Error:', err.message);
        console.log(JSON.stringify({ decision: 'continue' }));
      }
    }
    ```

    **Export:** Module is executable script, but also export `{ docCompressionHook }` for testing
  </action>
  <verify>
    ```bash
    # Test with mock hook input
    cd get-shit-done && echo '{"tool":"Read","tool_input":{"file_path":"/Users/ollorin/get-shit-done/.planning/phases/09-hook-based-documentation-compression-optimize-context-injection-by-extracting-ai-friendly-headers-from-docs-and-injecting-only-summaries-with-absolute-links-instead-of-full-content/09-RESEARCH.md"}}' | node bin/hooks/doc-compression-hook.js

    # Should output JSON with additionalContext containing compressed summary
    # Or decision: continue if file is too small

    # Test fallback on non-doc file
    echo '{"tool":"Read","tool_input":{"file_path":"/some/code.js"}}' | node bin/hooks/doc-compression-hook.js
    # Should output: {"decision":"continue"}

    # Test fallback on error
    echo 'invalid json' | node bin/hooks/doc-compression-hook.js
    # Should output: {"decision":"continue"}
    ```
  </verify>
  <done>Hook handler intercepts Read calls, compresses documentation files, injects via additionalContext, gracefully falls back on errors</done>
</task>

<task type="auto">
  <name>Task 3: Extend hook config with compression settings</name>
  <files>get-shit-done/bin/hooks/config.js</files>
  <action>
    Extend the existing Phase 4 hook config (`get-shit-done/bin/hooks/config.js`) to include compression settings:

    **Add to DEFAULT_HOOK_CONFIG:**
    ```javascript
    compression: {
      enabled: true,
      strategy: 'header-extraction',  // 'header-extraction' | 'semantic-filter'
      min_file_lines: 500,            // Skip if file smaller
      min_file_bytes: 15360,          // 15KB minimum
      target_reduction: 65,           // Percent - aim for 65% token reduction
      cache_ttl: 300,                 // Seconds - cache expiry (5 min)
      patterns: [
        '**/*-RESEARCH.md',
        '**/*-PLAN.md',
        '**/*-CONTEXT.md',
        '**/STATE.md',
        '**/ROADMAP.md',
        '**/PROJECT.md',
        '**/REQUIREMENTS.md'
      ],
      exclude: [
        '**/*-SUMMARY.md',            // Already compressed
        '**/.compressed/**',          // Cache directory
        '**/README.md'                // Usually short
      ],
      fallback: 'pass-through',       // 'pass-through' | 'error'
      circuit_breaker: {
        enabled: true,
        failure_threshold: 3,         // Disable after 3 consecutive failures
        reset_timeout: 300            // Re-enable after 5 minutes
      }
    }
    ```

    **Add helper functions:**
    - `loadCompressionConfig()` - returns merged compression config
    - `isCompressionEnabled()` - checks if compression is enabled
    - `setCompressionEnabled(enabled)` - toggle compression on/off
    - `updateCompressionSetting(key, value)` - update individual setting

    **Merge behavior:**
    - Deep merge with defaults for nested objects (patterns, circuit_breaker)
    - Allow override via `.planning/knowledge/hooks.json` (project-level)
    - Allow override via `~/.claude/knowledge/hooks.json` (global)

    **Export additions:**
    - Add to existing exports: `loadCompressionConfig`, `isCompressionEnabled`, `setCompressionEnabled`, `updateCompressionSetting`
  </action>
  <verify>
    ```bash
    cd get-shit-done && node -e "
    const {
      loadHookConfig,
      loadCompressionConfig,
      isCompressionEnabled
    } = require('./bin/hooks/config');

    console.log('Full config:', JSON.stringify(loadHookConfig(), null, 2));
    console.log('');
    console.log('Compression config:', JSON.stringify(loadCompressionConfig(), null, 2));
    console.log('Compression enabled:', isCompressionEnabled());
    "
    ```
    Should show merged config with compression section, enabled by default.
  </verify>
  <done>Hook config extended with compression settings, helper functions for toggling and updating, proper merge with defaults</done>
</task>

</tasks>

<verification>
End-to-end hook test simulating Claude Code PreToolUse:

```bash
cd get-shit-done && node -e "
const fs = require('fs');
const { execSync } = require('child_process');

// Simulate PreToolUse hook call
const hookInput = JSON.stringify({
  tool: 'Read',
  tool_input: {
    file_path: process.cwd() + '/../.planning/phases/09-hook-based-documentation-compression-optimize-context-injection-by-extracting-ai-friendly-headers-from-docs-and-injecting-only-summaries-with-absolute-links-instead-of-full-content/09-RESEARCH.md'
  }
});

// Run hook
const result = execSync('node bin/hooks/doc-compression-hook.js', {
  input: hookInput,
  encoding: 'utf8'
});

const output = JSON.parse(result);
console.log('Decision:', output.decision);
console.log('Has additionalContext:', !!output.additionalContext);

if (output.additionalContext) {
  console.log('');
  console.log('=== Compressed Summary Preview ===');
  console.log(output.additionalContext.slice(0, 800) + '...');
}
"
```

Expected: Hook returns `decision: continue` with `additionalContext` containing compressed 09-RESEARCH.md.
</verification>

<success_criteria>
- Hook handler processes Read tool calls from stdin
- Documentation files matching patterns are compressed
- Compressed content injected via additionalContext
- Files below size threshold pass through uncompressed
- Cache prevents redundant compression
- All errors gracefully fall back to `{"decision": "continue"}`
- Config extended with compression settings
</success_criteria>

<output>
After completion, create `.planning/phases/09-hook-based-documentation-compression-optimize-context-injection-by-extracting-ai-friendly-headers-from-docs-and-injecting-only-summaries-with-absolute-links-instead-of-full-content/09-02-SUMMARY.md`
</output>
