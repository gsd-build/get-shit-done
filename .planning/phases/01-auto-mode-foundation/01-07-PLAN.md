---
phase: 01-auto-mode-foundation
plan: 07
type: execute
wave: 1
depends_on: []
files_modified:
  - ~/.claude/get-shit-done/bin/gsd-tools.js
  - /Users/ollorin/get-shit-done/get-shit-done/bin/gsd-tools.js
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "System computes a 0-100 complexity score for any task description combining keyword signal, task length, and structural markers"
    - "Score ≤30 maps to haiku, 31-70 maps to sonnet, 71+ maps to opus"
    - "Existing selectModelFromRules behavior preserved — regex matching still works as the keyword signal source"
    - "routing match command returns score and tier breakdown in addition to model name"
  artifacts:
    - path: "~/.claude/get-shit-done/bin/gsd-tools.js"
      provides: "computeComplexityScore() function + updated selectModelFromRules() with score-based tier mapping"
      contains: "computeComplexityScore"
    - path: "/Users/ollorin/get-shit-done/get-shit-done/bin/gsd-tools.js"
      provides: "Mirror of above — project copy kept in sync"
      contains: "computeComplexityScore"
  key_links:
    - from: "selectModelFromRules()"
      to: "computeComplexityScore()"
      via: "score = computeComplexityScore(taskDesc, rules); model = scoreToTier(score)"
      pattern: "computeComplexityScore"
    - from: "cmdRoutingMatch()"
      to: "selectModelFromRules()"
      via: "result includes score and signals breakdown"
      pattern: "score.*signals"
---

<objective>
Implement multi-signal complexity scoring algorithm inside the existing gsd-tools.js routing system.

Purpose: AUTO-01 and AUTO-02 require graduated complexity detection (0-100 scale) mapping to model tiers. Current implementation only does binary regex matching — patterns either match or fall back to sonnet. This gap means routing is always maximum model for matched patterns, never graduated by actual complexity.

Output: `computeComplexityScore()` function replacing the winner-takes-all regex approach with a scored system. Both gsd-tools.js copies updated identically.
</objective>

<execution_context>
@/Users/ollorin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ollorin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@/Users/ollorin/get-shit-done/.planning/PROJECT.md
@/Users/ollorin/get-shit-done/.planning/STATE.md
@/Users/ollorin/get-shit-done/.planning/phases/01-auto-mode-foundation/01-CONTEXT.md
@/Users/ollorin/get-shit-done/.planning/phases/01-auto-mode-foundation/01-VERIFICATION.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add computeComplexityScore() to gsd-tools.js routing section</name>
  <files>
    ~/.claude/get-shit-done/bin/gsd-tools.js
    /Users/ollorin/get-shit-done/get-shit-done/bin/gsd-tools.js
  </files>
  <action>
In both gsd-tools.js files, locate the routing section around line 7519 (comment: "// Routing: model selection + context injection (Phase 01)").

After the `mergeRoutingRules()` function and BEFORE `selectModelFromRules()`, insert the `computeComplexityScore()` function.

The scoring algorithm combines three signals into a 0-100 score:

**Signal 1 — Keyword model weight (0-50 points):**
- Run the existing regex matching against all rules
- Collect all matching rules (not just highest priority)
- Each matching rule contributes points based on its model tier:
  - haiku match: 5 points per match (capped at 15)
  - sonnet match: 15 points per match (capped at 30)
  - opus match: 30 points per match (capped at 50)
- Use the maximum accumulated score across matching rules as signal 1
- If no rules match: 25 points (sonnet-default territory)

**Signal 2 — Task length (0-25 points):**
- Count words in the task description
- 1-20 words: 5 points (short, probably simple)
- 21-50 words: 12 points (medium)
- 51-100 words: 18 points (detailed)
- 100+ words: 25 points (complex specification)

**Signal 3 — Structural markers (0-25 points):**
Scan the task description text for markers that indicate complexity:
- Code block markers (``` or `inline`) present: +8 points
- Multiple bullet points (3+) present: +5 points
- Nested indicators (sub-bullets, indentation): +5 points
- Multiple numbered steps (3+): +5 points
- Architectural keywords ("design", "architecture", "system", "integrate", "migrate", "refactor", "evaluate"): +8 points
- Cross-cutting concerns ("security", "performance", "scalability", "all", "entire", "across"): +6 points
- Negation/constraints ("must not", "never", "always", "required", "must"): +3 points
Cap signal 3 at 25 points.

**Final score:** `signal1 + signal2 + signal3` (max 100)

**Tier mapping:**
- score <= 30 → 'haiku'
- score 31-70 → 'sonnet'
- score >= 71 → 'opus'

The function signature:
```javascript
function computeComplexityScore(taskDesc, rules) {
  // Returns { score, tier, signals: { keyword, length, structural } }
}
```

**Then update `selectModelFromRules()` to use this function:**
Replace the current winner-takes-all regex approach with:
1. Call `computeComplexityScore(taskDesc, rules)` to get score and tier
2. Also track the highest-priority matching rule for its rationale
3. Return:
```javascript
{
  model: tier,  // from score-based tier mapping
  reason: `complexity score ${score}/100 (keyword:${signals.keyword}, length:${signals.length}, structural:${signals.structural})`,
  matched: matchedRule !== null,
  pattern: matchedRule ? matchedRule.patterns.join(',') : null,
  score: score,
  signals: signals
}
```

If no patterns match AND score is in default territory (near 25 from signal 1 default):
- reason: `default (no pattern match) — score ${score}/100`

Apply the SAME changes to BOTH files:
- `~/.claude/get-shit-done/bin/gsd-tools.js`
- `/Users/ollorin/get-shit-done/get-shit-done/bin/gsd-tools.js`

Both files are 9788 lines and identical in structure. Make the same edit to both.
  </action>
  <verify>
Test the routing match command against known task descriptions:

```bash
node ~/.claude/get-shit-done/bin/gsd-tools.js routing match "fix typo in README" --json
# Expected: score <= 30, model: haiku

node ~/.claude/get-shit-done/bin/gsd-tools.js routing match "add delete endpoint to user API" --json
# Expected: score 31-70, model: sonnet

node ~/.claude/get-shit-done/bin/gsd-tools.js routing match "design multi-tenant authentication architecture with OAuth2, JWT refresh tokens, and role-based access control across all services" --json
# Expected: score >= 71, model: opus
```

Verify the output includes `score` and `signals` fields.

Also verify the project copy is identical:
```bash
node /Users/ollorin/get-shit-done/get-shit-done/bin/gsd-tools.js routing match "fix typo" --json
```
  </verify>
  <done>
- `computeComplexityScore()` function exists in both gsd-tools.js files
- `routing match` returns `score` (0-100 integer) and `signals` (object with keyword/length/structural breakdown) in addition to model
- "fix typo" type tasks score ≤30 → haiku
- Medium API/code tasks score 31-70 → sonnet
- Architecture/design tasks with multiple signals score ≥71 → opus
- Both file copies produce identical output for same input
  </done>
</task>

</tasks>

<verification>
```bash
# Verify function exists in both files
grep -c "computeComplexityScore" ~/.claude/get-shit-done/bin/gsd-tools.js
grep -c "computeComplexityScore" /Users/ollorin/get-shit-done/get-shit-done/bin/gsd-tools.js
# Both should return >= 2 (definition + call)

# Verify score field present in routing output
node ~/.claude/get-shit-done/bin/gsd-tools.js routing match "implement caching middleware" --json | grep -q '"score"' && echo PASS || echo FAIL

# Verify tier boundaries
node ~/.claude/get-shit-done/bin/gsd-tools.js routing match "fix typo" --json | python3 -c "import sys,json; d=json.load(sys.stdin); print('PASS' if d.get('model')=='haiku' else 'FAIL: '+d.get('model','?'))"
```
</verification>

<success_criteria>
AUTO-01 satisfied: System uses multi-signal analysis (keyword patterns + length + structural markers) to detect task complexity.
AUTO-02 satisfied: Complexity score (0-100) maps to model tiers (Haiku ≤30, Sonnet 31-70, Opus ≥71).
Both gsd-tools.js files updated identically.
`routing match` returns score and signals breakdown.
</success_criteria>

<output>
After completion, create `/Users/ollorin/get-shit-done/.planning/phases/01-auto-mode-foundation/01-07-SUMMARY.md`
</output>
